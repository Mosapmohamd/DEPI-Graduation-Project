{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mosapmohamd/DEPI-Graduation-Project/blob/main/Text_Preprocessing_%26_Annotation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7otg__ASXz_"
      },
      "source": [
        "# **Data annotation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L3sA2nhSqa1"
      },
      "source": [
        "# Import required dependences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import torch\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3h3SnUqPQh6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Egypt_Tourism_Reviews.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35Bqf1ZGUUGJ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('preprocessed_tourism_reviewsv2.csv')\n",
        "df = df[df['word_count'] < 384] # limit due to transformers 512 token limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT78EWcPUYJV"
      },
      "outputs": [],
      "source": [
        "# Method 1: Roberta Transformer  \n",
        "def label_with_roberta(df, text_column, model_name=\"siebert/sentiment-roberta-large-english\"):\n",
        "    sentiment_analyzer = pipeline(\"sentiment-analysis\", model=model_name, device=0 if device == 'cuda' else -1)\n",
        "    batch_size = 32\n",
        "    results = []\n",
        "    for i in tqdm(range(0, len(df), batch_size), desc=\"Roberta Transformer\"):\n",
        "        batch = df[text_column].iloc[i:i+batch_size].tolist()\n",
        "        outputs = sentiment_analyzer(batch, truncation=True)\n",
        "        results.extend(outputs)\n",
        "    labels = [result['label'] for result in results]\n",
        "    scores = [result['score'] for result in results]\n",
        "    sentiment_map = {'POSITIVE': 'positive', 'NEGATIVE': 'negative'}\n",
        "    final_labels = [sentiment_map.get(label, label.lower()) for label in labels]\n",
        "    return final_labels, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-u1bry6Uaj3"
      },
      "outputs": [],
      "source": [
        "# Method 2: VADER Sentiment Analysis\n",
        "def label_with_vader(df, text_column):\n",
        "    # Download VADER lexicon if not present\n",
        "    try:\n",
        "        nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "    except LookupError:\n",
        "        nltk.download('vader_lexicon')\n",
        "    \n",
        "    # Initialize VADER sentiment analyzer\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    scores = []\n",
        "    \n",
        "    # Process each text with progress bar\n",
        "    for text in tqdm(df[text_column], desc=\"VADER Binary\"):\n",
        "        if isinstance(text, str):\n",
        "            sentiment_dict = sid.polarity_scores(text)\n",
        "            scores.append(sentiment_dict)\n",
        "        else:\n",
        "            scores.append({'compound': 0, 'neg': 0, 'neu': 0, 'pos': 0})\n",
        "    \n",
        "    # Extract compound scores\n",
        "    compound_scores = [score['compound'] for score in scores]\n",
        "    \n",
        "    # Assign binary labels: positive (â‰¥ 0) or negative (< 0)\n",
        "    labels = ['positive' if score >= 0 else 'negative' for score in compound_scores]\n",
        "    \n",
        "    return labels, compound_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCu0hx2eUd_J"
      },
      "outputs": [],
      "source": [
        "def label_with_bert_binary(df, text_column, model_name=\"distilbert-base-uncased-finetuned-sst-2-english\"):\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
        "    print(f\"Distilbert Model is on device: {next(model.parameters()).device}\")\n",
        "    \n",
        "    labels = []\n",
        "    scores = []\n",
        "    batch_size = 32\n",
        "    \n",
        "    # Process reviews in batches\n",
        "    for i in tqdm(range(0, len(df), batch_size), desc=\"Distilbert Transformer\"):\n",
        "        batch_texts = df[text_column].iloc[i:i+batch_size].tolist()\n",
        "        # Ensure all inputs are strings\n",
        "        batch_texts = [str(text) if isinstance(text, str) else \"\" for text in batch_texts]\n",
        "        \n",
        "        # Tokenize batch\n",
        "        encoded_batch = tokenizer(batch_texts, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "        encoded_batch = {k: v.to(device) for k, v in encoded_batch.items()}  # Move to GPU\n",
        "        \n",
        "        # Get model predictions\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**encoded_batch)\n",
        "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        \n",
        "        # Get predicted classes and confidence scores\n",
        "        predicted_classes = predictions.argmax(dim=1).tolist()\n",
        "        max_scores = predictions.max(dim=1).values.tolist()\n",
        "        \n",
        "        # Map to binary labels: 0 -> negative, 1 -> positive\n",
        "        batch_labels = ['negative' if label == 0 else 'positive' for label in predicted_classes]\n",
        "        \n",
        "        labels.extend(batch_labels)\n",
        "        scores.extend(max_scores)\n",
        "    \n",
        "    return labels, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KVRVtGUUmd9"
      },
      "outputs": [],
      "source": [
        "# Apply models\n",
        "text_column = 'review'\n",
        "labels_binary, scores_binary = label_with_binary_transformer(df, text_column)\n",
        "labels_vader, scores_vader = label_with_vader(df, text_column)\n",
        "labels_three_class, scores_three_class = label_with_bert(df, text_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZWcyAnUUqJ5"
      },
      "outputs": [],
      "source": [
        "df['sentiment_binary'] = labels_binary\n",
        "df['sentiment_score_binary'] = scores_binary\n",
        "df['sentiment_vader'] = labels_vader\n",
        "df['sentiment_score_vader'] = scores_vader\n",
        "df['sentiment_three_class'] = labels_three_class\n",
        "df['sentiment_score_three_class'] = scores_three_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjqjr0OEUq3i"
      },
      "outputs": [],
      "source": [
        "# Ensemble Method: Majority Voting - hard voting\n",
        "def ensemble_sentiment(row):\n",
        "    sentiments = [row['sentiment_binary'], row['sentiment_vader'], row['sentiment_three_class']]\n",
        "    sentiment_counts = Counter(sentiments)\n",
        "    most_common = sentiment_counts.most_common(1)[0][0]\n",
        "    return most_common\n",
        "\n",
        "df['sentiment_ensemble'] = df.apply(ensemble_sentiment, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7975XcHU0-4"
      },
      "outputs": [],
      "source": [
        "df.to_csv('labeled_tourism_reviews.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMrG1Y7C7gLXGmYsOx+Z4l0",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
