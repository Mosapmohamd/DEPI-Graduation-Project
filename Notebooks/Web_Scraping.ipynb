{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSAZZaTjPb3m3Kj43J08+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mosapmohamd/DEPI-Graduation-Project/blob/main/Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TripAdvisor**"
      ],
      "metadata": {
        "id": "UNvUeK4kFiZR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4AD6adID98z"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "from dateutil.parser import parse as date_parse\n",
        "\n",
        "\n",
        "# Declare global lists so they can be used in other cells\n",
        "first_part = []\n",
        "last_part = []\n",
        "\n",
        "def split_url(url):\n",
        "    \"\"\"\n",
        "    Splits the given URL into two parts:\n",
        "      - first_part: everything from the start up to (and including) the substring \"Reviews\"\n",
        "      - last_part: the remainder of the URL (expected to start with '-')\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL to split.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (first_part, last_part)\n",
        "    \"\"\"\n",
        "    keyword = \"Reviews\"\n",
        "    idx = url.find(keyword)\n",
        "    if idx == -1:\n",
        "        raise ValueError(\"The keyword 'Reviews' was not found in the URL.\")\n",
        "\n",
        "    # Calculate the split index after the keyword \"Reviews\"\n",
        "    split_idx = idx + len(keyword)\n",
        "    first_part = url[:split_idx]\n",
        "    last_part = url[split_idx:]\n",
        "\n",
        "    # Warn if the last part doesn't start with '-' as expected.\n",
        "    if last_part and last_part[0] != '-':\n",
        "        print(f\"Warning: For URL '{url}', the last part does not start with '-' as expected.\")\n",
        "\n",
        "    return first_part, last_part\n",
        "\n",
        "def process_urls(file_path):\n",
        "    \"\"\"\n",
        "    Reads a file from the provided file path, processes each URL,\n",
        "    and appends the resulting parts to the global lists: first_parts and last_parts.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The file path to the .txt file containing URLs.\n",
        "    \"\"\"\n",
        "    global first_part, last_part\n",
        "    with open(file_path, 'r',encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            url = line.strip()\n",
        "            if not url:\n",
        "                continue  # Skip empty lines\n",
        "            try:\n",
        "                first, last = split_url(url)\n",
        "                first_part.append(first)\n",
        "                last_part.append(last)\n",
        "            except ValueError as e:\n",
        "                print(f\"Error processing URL '{url}': {e}\")\n",
        "\n",
        "# Provide the file path to your uploaded .txt file.\n",
        "# For example, if you uploaded 'urls.txt' to the root of your Colab environment, use:\n",
        "file_path = 'url.txt'\n",
        "\n",
        "# Process the file and update the global lists.\n",
        "process_urls(file_path)\n",
        "\n",
        "\n",
        "proxies = [\n",
        "    \"http://156.233.72.96:3128\",\n",
        "    \"http://156.228.110.5:3128\",\n",
        "    \"http://156.233.73.89:3128\",\n",
        "    \"http://156.228.105.152:3128\",\n",
        "    \"http://45.202.76.41:3128\",\n",
        "    \"http://156.249.138.159:3128\",\n",
        "    \"http://104.207.52.201:3128\",\n",
        "    \"http://104.207.53.27:3128\",\n",
        "    \"http://156.228.100.111:3128\",\n",
        "    \"http://104.207.54.164:3128\",\n",
        "    \"http://156.228.100.203:3128\",\n",
        "    \"http://154.91.171.200:3128\",\n",
        "    \"http://156.253.169.42:3128\",\n",
        "    \"http://154.213.194.182:3128\",\n",
        "    \"http://154.213.196.184:3128\",\n",
        "    \"http://156.228.90.69:3128\",\n",
        "    \"http://156.228.116.184:3128\",\n",
        "    \"http://156.228.179.98:3128\",\n",
        "    \"http://104.207.56.33:3128\",\n",
        "    \"http://156.253.175.47:3128\",\n",
        "    \"http://156.228.80.6:3128\",\n",
        "    \"http://154.94.14.207:3128\",\n",
        "    \"http://156.228.81.54:3128\",\n",
        "    \"http://156.228.113.20:3128\",\n",
        "    \"http://104.207.63.104:3128\",\n",
        "    \"http://156.233.90.81:3128\",\n",
        "    \"http://156.228.119.130:3128\",\n",
        "    \"http://156.233.88.102:3128\",\n",
        "    \"http://154.213.197.120:3128\",\n",
        "    \"http://156.228.95.24:3128\",\n",
        "    \"http://156.228.96.52:3128\",\n",
        "    \"http://156.228.119.236:3128\",\n",
        "    \"http://156.253.167.150:3128\",\n",
        "    \"http://156.228.182.202:3128\",\n",
        "    \"http://104.207.52.100:3128\",\n",
        "    \"http://104.207.39.225:3128\",\n",
        "    \"http://156.233.85.250:3128\",\n",
        "    \"http://156.228.76.69:3128\",\n",
        "    \"http://104.207.60.231:3128\",\n",
        "    \"http://156.233.90.171:3128\",\n",
        "    \"http://156.233.86.2:3128\",\n",
        "    \"http://156.228.85.40:3128\",\n",
        "    \"http://104.207.55.108:3128\",\n",
        "    \"http://156.228.112.143:3128\",\n",
        "    \"http://156.233.92.3:3128\",\n",
        "    \"http://156.253.178.232:3128\",\n",
        "    \"http://156.228.184.141:3128\",\n",
        "    \"http://154.94.15.146:3128\",\n",
        "    \"http://156.228.101.4:3128\",\n",
        "    \"http://156.253.170.36:3128\",\n",
        "    \"http://154.213.194.210:3128\",\n",
        "    \"http://154.213.198.148:3128\",\n",
        "    \"http://156.253.173.252:3128\",\n",
        "    \"http://45.202.76.108:3128\",\n",
        "    \"http://156.233.88.108:3128\",\n",
        "    \"http://156.253.179.137:3128\",\n",
        "    \"http://156.228.125.94:3128\",\n",
        "    \"http://156.253.167.33:3128\",\n",
        "    \"http://104.207.44.160:3128\",\n",
        "    \"http://156.228.117.192:3128\",\n",
        "    \"http://156.228.86.190:3128\",\n",
        "    \"http://154.94.14.5:3128\",\n",
        "    \"http://156.228.185.147:3128\",\n",
        "    \"http://156.228.84.39:3128\",\n",
        "    \"http://156.228.111.6:3128\",\n",
        "    \"http://154.94.13.104:3128\",\n",
        "    \"http://154.213.198.35:3128\",\n",
        "    \"http://156.253.164.55:3128\",\n",
        "    \"http://156.228.178.61:3128\",\n",
        "    \"http://156.228.97.74:3128\",\n",
        "    \"http://104.207.49.197:3128\",\n",
        "    \"http://156.228.77.213:3128\",\n",
        "    \"http://156.228.115.227:3128\",\n",
        "    \"http://156.228.115.66:3128\",\n",
        "    \"http://156.228.105.86:3128\",\n",
        "    \"http://156.228.102.177:3128\",\n",
        "    \"http://156.228.110.133:3128\",\n",
        "    \"http://104.207.62.242:3128\",\n",
        "    \"http://156.228.99.14:3128\",\n",
        "    \"http://156.228.103.174:3128\",\n",
        "    \"http://104.207.57.66:3128\",\n",
        "    \"http://156.228.118.128:3128\",\n",
        "    \"http://156.253.177.95:3128\",\n",
        "    \"http://156.228.86.91:3128\",\n",
        "    \"http://104.207.36.124:3128\",\n",
        "    \"http://156.233.92.128:3128\",\n",
        "    \"http://156.253.178.105:3128\",\n",
        "    \"http://156.233.73.247:3128\",\n",
        "    \"http://156.228.76.31:3128\",\n",
        "    \"http://104.167.25.211:3128\",\n",
        "    \"http://156.228.189.222:3128\",\n",
        "    \"http://156.233.75.87:3128\",\n",
        "    \"http://156.233.95.255:3128\",\n",
        "    \"http://156.233.92.40:3128\",\n",
        "    \"http://104.207.37.94:3128\",\n",
        "    \"http://104.167.27.168:3128\",\n",
        "    \"http://104.207.43.35:3128\",\n",
        "    \"http://156.228.189.23:3128\",\n",
        "    \"http://156.253.168.186:3128\",\n",
        "    \"http://156.228.91.33:3128\"\n",
        "]\n",
        "\n",
        "\n",
        "file_name = 'tripadvisor12k.csv'\n",
        "file_exists = os.path.exists(file_name)\n",
        "\n",
        "if file_exists:\n",
        "  check = pd.read_csv(file_name)\n",
        "  check = check.tail(1)\n",
        "  check = check['id'].values[0]\n",
        "\n",
        "\n",
        "USER_AGENTS = [\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\",\n",
        "\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\",\n",
        "\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\",\n",
        "\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:119.0) Gecko/20100101 Firefox/119.0\",\n",
        "\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:120.0) Gecko/20100101 Firefox/120.0\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:119.0) Gecko/20100101 Firefox/119.0\",\n",
        "\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0\",\n",
        "\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Version/16.1 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Version/15.6 Safari/537.36\",\n",
        "\n",
        "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_1_1 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 16_6_1 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/537.36\",\n",
        "\n",
        "    \"Mozilla/5.0 (Linux; Android 14; SM-S918B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Mobile Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Linux; Android 13; Pixel 7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Linux; Android 12; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Mobile Safari/537.36\",\n",
        "]\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": random.choice(USER_AGENTS),\n",
        "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Referer\": \"https://www.google.com/\",\n",
        "    \"Connection\": \"keep-alive\",\n",
        "    \"Upgrade-Insecure-Requests\": \"1\",\n",
        "    \"Cache-Control\": \"max-age=0\",\n",
        "    \"Sec-Fetch-Site\": \"same-origin\",\n",
        "    \"Sec-Fetch-Mode\": \"navigate\",\n",
        "    \"Sec-Fetch-Dest\": \"document\"\n",
        "}\n",
        "\n",
        "p_num = 60\n",
        "review_id = check + 1 if file_exists else 1\n",
        "loc = 0\n",
        "proxy_index = 0\n",
        "while True:\n",
        "    url = first_part[loc] + last_part[loc] if p_num == 0 else f\"{first_part[loc]}-or{p_num}{last_part[loc]}\"\n",
        "    print(f\"Fetching reviews from: {url}\")\n",
        "    proxy_index = (proxy_index + 1) % len(proxies)\n",
        "    proxy = proxies[proxy_index]\n",
        "    print(f\"Using proxy: {proxy}\")\n",
        "    response = requests.get(url, proxies={'http': proxy}, timeout=30, headers=headers)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
        "        proxies.remove(proxy)\n",
        "        headers[\"User-Agent\"] = random.choice(USER_AGENTS)\n",
        "        continue\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'lxml')\n",
        "    review_containers = soup.find_all('div', attrs={'data-automation': 'reviewCard'})\n",
        "\n",
        "    if not review_containers and loc < len(first_part):\n",
        "        print(\"No more reviews found. Switching to next location.\")\n",
        "        loc += 1\n",
        "        p_num = 0\n",
        "        continue\n",
        "    elif not review_containers and loc == len(first_part):\n",
        "        print(\"No more reviews found. Exiting.\")\n",
        "        break\n",
        "\n",
        "    # Collect reviews for the current page\n",
        "    reviews = []\n",
        "    for review in review_containers:\n",
        "        rating_svg = review.find('svg', class_='UctUV d H0')\n",
        "        rating_text = rating_svg.find('title').get_text(strip=True) if rating_svg and rating_svg.find('title') else \"N/A\"\n",
        "        rate_num = float(rating_text.split()[0]) if rating_text != \"N/A\" else None\n",
        "\n",
        "        review_text_container = review.find('div', class_='fIrGe _T bgMZj')\n",
        "        review_text_span = review_text_container.find('span', class_='yCeTE') if review_text_container else None\n",
        "        review_text = review_text_span.get_text(strip=True) if review_text_span else \"N/A\"\n",
        "\n",
        "        date_container = review.find('div', class_='TreSq')\n",
        "        date_div = date_container.find('div', class_='biGQs _P pZUbB ncFvv osNWb') if date_container else None\n",
        "        date_text = date_div.get_text(strip=True) if date_div else \"N/A\"\n",
        "\n",
        "        if date_text.lower().startswith(\"written\"):\n",
        "            date_text = date_text[len(\"written\"):].strip()\n",
        "            date_str = date_parse(date_text).strftime(\"%Y-%m-%d\")\n",
        "        else:\n",
        "            date_str = \"N/A\"\n",
        "\n",
        "        attraction_name = soup.find('h1', class_='biGQs _P fiohW eIegw')\n",
        "        attraction = attraction_name.contents[0].strip() if attraction_name else \"N/A\"\n",
        "\n",
        "        sentiment = 'N/A'\n",
        "        if rate_num == 3:\n",
        "            sentiment = 'Neutral'\n",
        "        elif rate_num and rate_num > 3:\n",
        "            sentiment = 'Positive'\n",
        "        elif rate_num and rate_num < 3:\n",
        "            sentiment = 'Negative'\n",
        "\n",
        "        reviews.append({\n",
        "            'id': review_id,\n",
        "            'attraction': attraction,\n",
        "            'rate': rate_num if rate_num is not None else \"\",\n",
        "            'date': date_str,\n",
        "            'review': review_text,\n",
        "            'sentiment': sentiment\n",
        "        })\n",
        "        print(f\"Saved review {review_id}\")\n",
        "        review_id += 1\n",
        "\n",
        "    # Write the current page's reviews to CSV using pandas in append mode\n",
        "    if reviews:\n",
        "        df = pd.DataFrame(reviews)\n",
        "        df.to_csv(file_name, mode='a', header=not file_exists, index=False, encoding='utf-8')\n",
        "        file_exists = True\n",
        "\n",
        "    if proxy_index + 1 % 100 == 0:\n",
        "      proxies = random.shuffle(proxies)\n",
        "    p_num += 10\n",
        "    time.sleep(0.6 + random.random())\n",
        "    headers[\"User-Agent\"] = random.choice(USER_AGENTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Quora**"
      ],
      "metadata": {
        "id": "qOeTj-IAFquF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument(\"--headless\")\n",

        "\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "urls = [\n",
        "\n",
        "    \"https://www.quora.com/What-is-it-like-to-live-in-Egypt-on-a-daily-basis-Is-it-safe-to-raise-your-family-there\",\n",
        "    \"https://www.quora.com/How-was-your-experience-living-in-Egypt-as-a-foreigner\",\n",
        "    \"https://www.quora.com/What-is-it-like-for-a-foreigner-to-live-in-Egypt-Are-there-any-challenges-they-may-face-What-advice-would-you-give-to-someone-who-wants-to-permanently-move-to-Egypt\",\n",
        "    \"https://www.quora.com/What-are-some-challenges-unique-to-living-in-Cairo-Egypt\",\n",
        "    \"https://www.quora.com/How-is-life-in-Cairo-Egypt-for-a-foreign-person\",\n",
        "    \"https://www.quora.com/Is-it-a-good-place-for-a-girl-to-do-student-exchange-in-Cairo-Egypt-in-a-foreign-university-I-would-love-to-hear-some-opinions-from-the-Egyptian-people-or-the-foreigners-studying-there\",\n",
        "    \"https://www.quora.com/What-is-life-like-as-an-American-in-Cairo\",\n",
        "    \"https://www.quora.com/unanswered/What-do-you-do-for-a-living-in-the-city-of-Cairo-in-Egypt\",\n",
        "    \"https://www.quora.com/What-do-people-not-like-about-living-in-Cairo-Egypt\",\n",
        "\n",
        "    \"https://www.quora.com/What-should-I-absolutely-not-do-when-visiting-Egypt\",\n",
        "    \"https://www.quora.com/Would-you-recommend-visiting-Luxor-Egypt-Why-or-why-not\",\n",
        "    \"https://www.quora.com/Is-Egypt-really-beautiful-as-I-heard-Is-it-worth-travelling-to-as-tourists\",\n",
        "    \"https://www.quora.com/Is-it-safe-to-travel-to-Egypt-as-a-tourist-nowadays-Is-it-worth-going-there-now-or-would-it-be-better-to-wait-until-the-situation-is-more-stable\"\"https://www.quora.com/Why-do-people-advise-me-never-to-travel-to-Egypt\",\n",
        "    \"https://www.quora.com/What-should-I-absolutely-not-do-when-visiting-Egypt\",\n",
        "    \"https://www.quora.com/Can-you-describe-what-it-is-like-to-live-in-Egypt-Are-there-any-reasons-why-someone-should-not-visit-or-move-there\",\n",
        "    \"https://www.quora.com/What-is-it-like-to-live-in-Cairo-Egypt\",\n",
        "    \"https://www.quora.com/Why-is-Egypt-poor\",\n",
        "    \"https://www.quora.com/Is-visiting-Egypt-worth-it?topAns=1477743659443729\",\n",
        "    \"https://www.quora.com/Is-Egypt-worth-visiting-Are-the-pyramids-overhyped\",\n",
        "      \"https://www.quora.com/Whats-is-the-most-beautiful-place-in-Egypt\",\n",
        "    \"https://www.quora.com/Where-is-the-best-location-to-book-a-hotel-in-Cairo-Egypt\",\n",
        "    \"https://www.quora.com/Where-is-the-best-and-cheapest-place-to-stay-in-Cairo-in-Egypt\",\n",
        "    \"http://quora.com/How-much-does-it-cost-to-go-to-Cairo-Egypt-for-2-people-airfares-hotel-food-and-spending-included-or-at-least-an-estimate-price\",\n",
        "    \"https://www.quora.com/What-is-a-decent-clean-and-cheap-airport-hotel-for-a-stop-over-in-Cairo\",\n",
        "    \"https://www.quora.com/unanswered/Whats-the-worst-hotel-in-Cairo\",\n",
        "    \"https://www.quora.com/What-is-the-Worst-Thing-About-The-City-Of-Cairo-Egypt\",\n",
        "    \"https://www.quora.com/What-is-the-most-dangerous-neighborhood-in-Cairo-Egypt\",\n",
        "    \"https://www.quora.com/What-is-your-worst-experience-in-Cairo\",\n",
        "    \"https://www.quora.com/What-is-your-best-Only-In-Cairo-moment\",\n",
        "    \"https://www.quora.com/How-do-I-get-the-hell-out-of-Egypt\",\n",
        "    \"https://www.quora.com/What-is-food-in-Egypt-like\",\n",
        "    \"https://www.quora.com/What-is-unusual-or-different-about-the-food-and-cuisine-in-Egypt\",\n",
        "    \"https://www.quora.com/What-are-the-best-restaurants-to-try-when-visiting-Alexandria-Egypt-What-should-you-try-while-youre-there\",\n",
        "    \"https://www.quora.com/What-is-your-review-of-Alexandria-Egypt\",\n",
        "    \"https://www.quora.com/What-is-the-best-Thing-about-The-City-Of-Alexandria-Egypt\",\n",
        "    \"https://www.quora.com/Egypt-What-do-you-hate-the-most-about-being-an-Egyptian?topAns=19023978\",\n",
        "    \"https://www.quora.com/What-do-foreigners-find-most-annoying-about-Egyptians-and-Egypt\",\n",
        "    \"https://www.quora.com/Egypt-What-do-you-hate-the-most-about-being-an-Egyptian\",\n",
        "    \"https://www.quora.com/Is-it-safe-to-live-in-Egypt?topAns=65095491\",\n",
        "    \"https://www.quora.com/What-is-it-like-for-a-Indian-guy-to-live-in-Egypt\",\n",
        "     \"https://www.quora.com/Is-Cairo-safe-for-Indians-to-live-Do-Egyptians-treat-Indians-well\",\n",
        "     \"https://www.quora.com/Is-it-safe-for-me-to-accept-a-job-offer-in-Cairo-Is-it-safe-for-an-expat-Indian-origin\",\n",
        "     \"https://www.quora.com/How-safe-is-working-in-Cairo-Egypt-for-a-woman\",\n",
        "     \"https://www.quora.com/Egypt-What-do-you-hate-the-most-about-being-an-Egyptian\",\n",
        "     \"https://www.quora.com/What-are-some-characteristics-of-Egyptian-people\",\n",
        "     \"https://www.quora.com/What-are-the-major-characteristics-of-Egyptians\",\n",
        "     \"https://www.quora.com/What-are-the-pros-and-cons-of-marrying-an-Egyptian-man\",\n",
        "     \"https://www.quora.com/What-do-you-think-about-Egyptian-people\",\n",
        "     \"https://www.quora.com/Is-it-normal-that-I-hate-my-country-Egypt\",\n",
        "     \"https://www.quora.com/What-are-some-funny-facts-about-Egypt-Egyptian-people-and-culture\",\n",
        "     \"https://www.quora.com/Egypt-What-do-you-know-about-egyptian-people\",\n",
        "     \"https://www.quora.com/unanswered/Can-you-describe-what-its-like-to-be-a-woman-in-Cairo-Egypt\",\n",
        "     \"https://www.quora.com/What-is-the-most-dangerous-neighborhood-in-Cairo-Egypt\",\n",
        "     \"https://www.quora.com/How-safe-is-Egypt-and-how-are-the-people-and-communities-in-Cairo-How-much-would-you-rate-Cairo-out-of-10-in-terms-of-safety-for-a-woman-and-why\",\n",
        "     \"https://www.quora.com/How-safe-is-it-to-go-to-Cairo-Egypt-to-work-now-I-have-to-make-a-decision-on-a-job-opportunity-in-Egypt\",\n",
        "     \"https://www.quora.com/unanswered/Are-there-many-foreigners-living-permanently-in-Cairo-Egypt\"\n",
        "\n",
        "]\n",
        "\n",
        "all_data = []\n",
        "\n",
        "try:\n",
        "    for url in urls:\n",
        "        print(f\"\\nScraping: {url}\")\n",
        "        driver.get(url)\n",
        "\n",
        "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
        "\n",
        "        SCROLL_PAUSE_TIME = 10\n",
        "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "        for _ in range(10):\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(SCROLL_PAUSE_TIME)\n",
        "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "            if new_height == last_height:\n",
        "                break\n",
        "            last_height = new_height\n",
        "\n",
        "\n",
        "        WebDriverWait(driver, 30).until(\n",
        "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.q-text\"))\n",
        "        )\n",
        "\n",
        "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "        answer_containers = soup.find_all(\"div\", class_=\"q-box spacing_log_answer_content puppeteer_test_answer_content\")\n",
        "        data = []\n",
        "        for answer in answer_containers:\n",
        "            text = answer.get_text()\n",
        "            data.append([text])\n",
        "\n",
        "        file_path = \"Quora_Egypt_Tourism_Reviews.csv\"\n",
        "\n",
        "        new_data = pd.DataFrame(data, columns=[\"Answer\"])\n",
        "\n",
        "        try:\n",
        "            existing_data = pd.read_csv(file_path)\n",
        "            updated_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
        "        except FileNotFoundError:\n",
        "            updated_data = new_data\n",
        "\n",
        "        updated_data.to_csv(file_path, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred: {e}\")\n",
        "\n",
        "finally:\n",
        "    driver.quit()\n",
        "\n",
        "print(\"\\n Scraping complete. Saved to 'Quora_Egypt_Tourism_Reviews.csv'\")\n"
      ],
      "metadata": {
        "id": "qei204cVFVJa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
